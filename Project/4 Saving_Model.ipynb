{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ME17B158 - Omkar Nath\n",
    "\n",
    "ME17B170 - Uma T.V."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A compressed version of program 3, that creates a pipeline of the PCA-SVM file, and saves the model using Pickle for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data files used in the intermediary steps can be found at:<br>\n",
    "https://drive.google.com/drive/folders/1KZQGxsVdWbNpCf0-0EmXhnsaKcOin4wA?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import statsmodels.api as sm\n",
    "from sklearn.cluster import k_means\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the previously created modified files\n",
    "train=pd.read_csv('train_imputed.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seprating into x and y\n",
    "y_train=train['label']\n",
    "x_train=train.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Pipeline with all the models\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('pca',IncrementalPCA(n_components=120)),\n",
    "                 ('svc', GridSearchCV(estimator = SVC(), param_grid = {\"C\": [5]}, scoring= 'accuracy', \n",
    "                                      cv = KFold(n_splits=3,shuffle=True,random_state=42),\n",
    "                                      verbose = 1, return_train_score=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   39.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('pca', IncrementalPCA(n_components=120)),\n",
       "                ('svc',\n",
       "                 GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                              estimator=SVC(), param_grid={'C': [5]},\n",
       "                              return_train_score=True, scoring='accuracy',\n",
       "                              verbose=1))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model to the data\n",
    "pipe.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model pipeline\n",
    "pickle.dump(pipe, open(\"Model.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the model\n",
    "test_predict = pipe.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Predictions to the required format\n",
    "solution=pd.DataFrame()\n",
    "indices=[]\n",
    "for i in range(1000):\n",
    "    indices.append('Sample_'+str(i+1)) \n",
    "solution['Expected']=test_predict\n",
    "solution.index=indices\n",
    "solution.index.name = \"Id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the File\n",
    "solution.to_csv('Predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
