{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ME17B158 - Omkar Nath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Classification : Nearest Neighbors and Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Perform k-Nearest neighbours on the given dataset($X_{knn}$ and $y_{knn}$: where $X_{knn}$ stores feature vectors representing the movies and  $y_{knn}$ stores the 0-1 labelling for each movie) for binary classification of movies, for classifiying whether a given movie is a comedy(label 1) or not a comedy(label 0) . Split the dataset into train(80%), validation(10%) and test sets(10%).Run k-Nearest neighbours for different k values (1,3,7,15,31,63). Select the k, using validation set, which returns the best accuracy score. \n",
    "\n",
    "(i)  Report all the validation accuracies for all the values of k. \n",
    "<br>(ii) Report accuracy score by performing k-NN on the test dataset using the best chosen k value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_csv(\"X_knn.csv\", sep = ' ', header=None)\n",
    "y_df = pd.read_csv(\"y_knn.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1118</th>\n",
       "      <th>1119</th>\n",
       "      <th>1120</th>\n",
       "      <th>1121</th>\n",
       "      <th>1122</th>\n",
       "      <th>1123</th>\n",
       "      <th>1124</th>\n",
       "      <th>1125</th>\n",
       "      <th>1126</th>\n",
       "      <th>1127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.05775</td>\n",
       "      <td>0.09675</td>\n",
       "      <td>0.14675</td>\n",
       "      <td>0.21700</td>\n",
       "      <td>0.06700</td>\n",
       "      <td>0.26275</td>\n",
       "      <td>0.26200</td>\n",
       "      <td>0.03200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.04575</td>\n",
       "      <td>0.03275</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>0.04150</td>\n",
       "      <td>0.01925</td>\n",
       "      <td>0.03625</td>\n",
       "      <td>0.07775</td>\n",
       "      <td>0.02300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03975</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>0.03775</td>\n",
       "      <td>0.04800</td>\n",
       "      <td>0.11025</td>\n",
       "      <td>0.07250</td>\n",
       "      <td>0.04775</td>\n",
       "      <td>0.10975</td>\n",
       "      <td>0.09925</td>\n",
       "      <td>0.02050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04175</td>\n",
       "      <td>0.01925</td>\n",
       "      <td>0.01725</td>\n",
       "      <td>0.02425</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.01550</td>\n",
       "      <td>0.01475</td>\n",
       "      <td>0.09025</td>\n",
       "      <td>0.01875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04350</td>\n",
       "      <td>0.05475</td>\n",
       "      <td>0.02800</td>\n",
       "      <td>0.07700</td>\n",
       "      <td>0.05400</td>\n",
       "      <td>0.06850</td>\n",
       "      <td>0.05600</td>\n",
       "      <td>0.18500</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.02675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04150</td>\n",
       "      <td>0.02675</td>\n",
       "      <td>0.02775</td>\n",
       "      <td>0.03425</td>\n",
       "      <td>0.15550</td>\n",
       "      <td>0.03675</td>\n",
       "      <td>0.01700</td>\n",
       "      <td>0.01950</td>\n",
       "      <td>0.09700</td>\n",
       "      <td>0.01850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03725</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.03675</td>\n",
       "      <td>0.03100</td>\n",
       "      <td>0.06825</td>\n",
       "      <td>0.04050</td>\n",
       "      <td>0.02325</td>\n",
       "      <td>0.08700</td>\n",
       "      <td>0.05125</td>\n",
       "      <td>0.03025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05750</td>\n",
       "      <td>0.03375</td>\n",
       "      <td>0.02275</td>\n",
       "      <td>0.03975</td>\n",
       "      <td>0.18525</td>\n",
       "      <td>0.05925</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>0.01525</td>\n",
       "      <td>0.06450</td>\n",
       "      <td>0.01300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04200</td>\n",
       "      <td>0.05275</td>\n",
       "      <td>0.05925</td>\n",
       "      <td>0.03675</td>\n",
       "      <td>0.07525</td>\n",
       "      <td>0.12525</td>\n",
       "      <td>0.02850</td>\n",
       "      <td>0.08500</td>\n",
       "      <td>0.02950</td>\n",
       "      <td>0.02875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04250</td>\n",
       "      <td>0.02825</td>\n",
       "      <td>0.02150</td>\n",
       "      <td>0.02600</td>\n",
       "      <td>0.14275</td>\n",
       "      <td>0.02075</td>\n",
       "      <td>0.01650</td>\n",
       "      <td>0.01675</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.01825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0        1        2        3        4        5        6        7     \\\n",
       "0  0.02500  0.02500  0.05775  0.09675  0.14675  0.21700  0.06700  0.26275   \n",
       "1  0.03975  0.04375  0.03775  0.04800  0.11025  0.07250  0.04775  0.10975   \n",
       "2  0.04350  0.05475  0.02800  0.07700  0.05400  0.06850  0.05600  0.18500   \n",
       "3  0.03725  0.03950  0.03675  0.03100  0.06825  0.04050  0.02325  0.08700   \n",
       "4  0.04200  0.05275  0.05925  0.03675  0.07525  0.12525  0.02850  0.08500   \n",
       "\n",
       "      8        9     ...     1118     1119     1120     1121     1122  \\\n",
       "0  0.26200  0.03200  ...  0.03950  0.01800  0.04575  0.03275  0.12500   \n",
       "1  0.09925  0.02050  ...  0.04175  0.01925  0.01725  0.02425  0.12550   \n",
       "2  0.04925  0.02675  ...  0.04150  0.02675  0.02775  0.03425  0.15550   \n",
       "3  0.05125  0.03025  ...  0.05750  0.03375  0.02275  0.03975  0.18525   \n",
       "4  0.02950  0.02875  ...  0.04250  0.02825  0.02150  0.02600  0.14275   \n",
       "\n",
       "      1123     1124     1125     1126     1127  \n",
       "0  0.04150  0.01925  0.03625  0.07775  0.02300  \n",
       "1  0.02250  0.01550  0.01475  0.09025  0.01875  \n",
       "2  0.03675  0.01700  0.01950  0.09700  0.01850  \n",
       "3  0.05925  0.01500  0.01525  0.06450  0.01300  \n",
       "4  0.02075  0.01650  0.01675  0.10750  0.01825  \n",
       "\n",
       "[5 rows x 1128 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  0.0\n",
       "2  1.0\n",
       "3  1.0\n",
       "4  1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_df)\n",
    "y = np.array(y_df)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data\n",
    "X_train, X_val, X_test = np.split(X, [int(.8 * len(X)), int(.9 * len(X))])\n",
    "y_train, y_val, y_test = np.split(y, [int(.8 * len(y)), int(.9 * len(y))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals = [1,3,7,15,31,63]\n",
    "val_acc = []\n",
    "\n",
    "for k in k_vals:\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_val_pred = classifier.predict(X_val)\n",
    "    val_acc.append(accuracy_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k_vals, val_acc, 'bo-')\n",
    "plt.xticks(k_vals)\n",
    "plt.title(\"Validation Accuracy Score vs k\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy %\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    k  Validation Accuracy\n",
      "0   1                0.836\n",
      "1   3                0.863\n",
      "2   7                0.862\n",
      "3  15                0.867\n",
      "4  31                0.864\n",
      "5  63                0.860\n"
     ]
    }
   ],
   "source": [
    "# Score for different values k\n",
    "k_acc = {\"k\": k_vals, \"Validation Accuracy\": val_acc}\n",
    "print(pd.DataFrame(k_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The k with the best acc of  0.867  is  15\n"
     ]
    }
   ],
   "source": [
    "best_k = k_vals[val_acc.index(max(val_acc))]\n",
    "best_acc = max(val_acc)\n",
    "print(\"The k with the best acc of \",best_acc,\" is \",best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 86.7%\n"
     ]
    }
   ],
   "source": [
    "# Using the best k value\n",
    "classifier = KNeighborsClassifier(n_neighbors=best_k)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Test accuracy = {}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the results here:\n",
    "k=15 is the best as it gives the highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) State why using an even value of k in k-NN should not be chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With even k, it is possible for a perfect split i.e. half belonging to one class and half belonging to another. To avoid this, we always prefer odd k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Naive Bayes' classifier  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Continuous Distribution of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the distribution of the data( $X$ represents the datapoints and $Y$ represents the 0-1 binary-class label; where 0 being the negative class and 1 being the positive class) is already known.\n",
    "<br>Consider the following one-dimensional(1-D) Gaussian distributions where means and variances are unknown. You need to estimate means($\\mu_-$: for negative class and  $\\mu_+$: for positive class) and variances ($\\sigma^{2}_{-}$: for negative class and $\\sigma^{2}_+$: for positive class) from the given data : \n",
    "<br> (1) Assume $X|Y_{Y=0} \\sim \\mathcal{N}(\\mu_- , \\sigma^{2}_-)$ \n",
    "<br>(2) Assume $X|Y_{Y=1} \\sim \\mathcal{N}(\\mu_+ , \\sigma^{2}_+)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Generating artificial datasets in the next cell *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell is for generating datasets. Students should not change anything in this cell. \n",
    "## You can compare your mean and variance estimates by the actual ones used to generate these datasets\n",
    "\n",
    "X_pos = np.random.randn(1000,1)+np.array([[2.]])\n",
    "X_neg = np.random.randn(1000,1)+np.array([[4.]])\n",
    "X_train_pos = X_pos[:900]\n",
    "X_train_neg = X_neg[:900]\n",
    "X_test_pos = X_pos[900:]\n",
    "X_test_neg = X_neg[900:]\n",
    "X_train = np.concatenate((X_train_pos, X_train_neg), axis=0)\n",
    "X_test = np.concatenate((X_test_pos, X_test_neg), axis=0)\n",
    "Y_train = np.concatenate(( np.ones(900),np.zeros(900) ))\n",
    "Y_test = np.concatenate(( np.ones(100), np.zeros(100) ))\n",
    "\n",
    "## X_train, X_test, Y_train, Y_test are your datasets to work with ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>**Instructions to follow for learning a Baeysian classifier:** *(Code the formulae for estimating the different parameters yourself)*\n",
    "<br> a)Utilize the training dataset to estimate the means($\\hat{\\mu_+}$,$\\hat{\\mu_-}$) and variances($\\hat{\\sigma^{2}_+}$, $\\hat{\\sigma^{2}_-}$) for both positive and negative classes  \n",
    "b)Estimate the prior probability: $P(Y=1)$  ⟶ which could be referred to as: $\\hat{a}$ \n",
    "<br>c)Estimate the classifier funtion/posterior probability:  $P(Y=1|X = x)$  ⟶ which could be referred to as $\\hat{\\eta(x)}$\n",
    "<br>d)Find out the threshold value($x^*$) for classification by equating the estimated classifier function($\\hat{\\eta(x)}$)  with threshold probability of 0.5\n",
    "<br>e)Classify the test dataset into the two classes using this threshold value($x^*$) and find out the **accuracy** of the prediction \n",
    "\n",
    "Return back:  $\\hat{\\mu_+}$, $\\hat{\\mu_-}$, $\\hat{\\sigma^{2}_+}$, $\\hat{\\sigma^{2}_-}$, $\\hat{a}$, $x^*$ and accuracy from the code written \n",
    "\n",
    "*Hint: $X|Y_{Y=0} \\sim \\mathcal{N}(\\mu_- , \\sigma^{2}_-)$ implies $P_{X|Y=0} = \\mathcal{N}(\\mu_- , \\sigma^{2}_-) $*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Wise examples\n",
    "n1 = sum(Y_train==np.ones(len(Y_train)))\n",
    "n0 = len(Y_train) - n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean of positive class:  1.9795075854876019\n",
      "Estimated mean of negative class:  4.072973982524726\n"
     ]
    }
   ],
   "source": [
    "# Estimating Means\n",
    "sum1 = sum([x[0] for i,x in enumerate(X_train) if Y_train[i]==1])\n",
    "mean1 = float(sum1)/n1\n",
    "\n",
    "sum0 = sum([x[0] for i,x in enumerate(X_train) if Y_train[i]==0])\n",
    "mean0 = float(sum0)/n0\n",
    "\n",
    "print(\"Estimated mean of positive class: \", mean1)\n",
    "print(\"Estimated mean of negative class: \", mean0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated variance of positive class:  1.005749756360587\n",
      "Estimated variance of negative class:  0.9424458215491619\n"
     ]
    }
   ],
   "source": [
    "# Estimating Variances\n",
    "sum1 = sum([(x[0]-mean1)**2 for i,x in enumerate(X_train) if Y_train[i]==1])\n",
    "var1 = float(sum1)/(n1-1)\n",
    "\n",
    "sum0 = sum([(x[0]-mean0)**2 for i,x in enumerate(X_train) if Y_train[i]==0])\n",
    "var0 = float(sum0)/(n0-1)\n",
    "\n",
    "print(\"Estimated variance of positive class: \", var1)\n",
    "print(\"Estimated variance of negative class: \", var0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probability of the positive class: 0.5\n",
      "Prior probability of the negative class: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Estimating Prior Probabilities\n",
    "pr_pro1 = n1/len(Y_train)\n",
    "pr_pro0 = n0/len(Y_train)\n",
    "print(\"Prior probability of the positive class:\", pr_pro1)\n",
    "print(\"Prior probability of the negative class:\", pr_pro0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Function\n",
    "def Gaussian(x, mu, var):\n",
    "    return (1/np.sqrt(2*np.pi*var))*np.exp(-1*((x-mu)**2)/(2*var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold value =  3.027288564985662\n"
     ]
    }
   ],
   "source": [
    "# Threshold Value\n",
    "x_vals = np.linspace(mean1, mean0, 1000)\n",
    "differences = [None]*1000\n",
    "\n",
    "for i, x in enumerate(x_vals):\n",
    "    prob = (pr_pro1*Gaussian(x, mean1, var1))/(pr_pro1*Gaussian(x, mean1, var1)+pr_pro0*Gaussian(x, mean0, var0))\n",
    "    differences[i] = abs(0.5 - prob)\n",
    "    \n",
    "thresh = x_vals[differences.index(min(differences))]\n",
    "print(\"Threshold value = \", thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 85.27777777777777 %\n",
      "Test accuracy = 85.5 %\n"
     ]
    }
   ],
   "source": [
    "# Data Classification\n",
    "train_pred = X_train <= thresh\n",
    "train_result = train_pred[:, 0]==Y_train\n",
    "train_acc = np.mean(train_result)\n",
    "print(\"Training accuracy = {} %\".format(train_acc*100))\n",
    "\n",
    "test_pred = X_test <= thresh\n",
    "test_result = test_pred[:, 0]==Y_test\n",
    "test_acc = np.mean(test_result)\n",
    "print(\"Test accuracy = {} %\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write results here:\n",
    "\n",
    "* Estimated mean of positive class:  2.0005368139717863\n",
    "* Estimated mean of negative class:  4.0440233172920985\n",
    "\n",
    "* Estimated variance of positive class:  1.0025901106283377\n",
    "* Estimated variance of negative class:  1.0181743144310418\n",
    "\n",
    "* Threshold value =  3.0212572996142644\n",
    "\n",
    "* Training accuracy = 84.55555555555556 %\n",
    "* Test accuracy = 83.5 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Discrete distribution of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the first exercise for learning the Naive Bayes' classifier where we dealt with continuous distribution of data, here you need to work with discrete data, which means finding Probability Mass Distribution(PMF). \n",
    "\n",
    "Age  | Income | Status  | Buy\n",
    "-----|--------|-------- |----\n",
    "<=20 |  low   | students| yes\n",
    "<=20 |  high  | students| yes\n",
    "<=20 | medium | students| no\n",
    "<=20 | medium | married | no\n",
    "<=20 |  high  | married | yes\n",
    "21-30|  low   | married | yes\n",
    "21-30|  low   | married | no \n",
    "21-30| medium | students| no\n",
    "21-30|  high  | students| yes\n",
    " >30 |  high  | married | no\n",
    " >30 |  high  | married | yes\n",
    " >30 | medium | married | yes\n",
    " >30 | medium | married | no\n",
    " >30 | medium | students| no\n",
    " \n",
    "Consider the train dataset above. Take any random datapoint ($X_{i}$) where $X_{i} = (X_{i,1} = Age,X_{i,2} = Income,X_{i,3} = Status)$ and its corresponding label \n",
    "\n",
    "($Y_{i} = Buy$). A \"yes\" in Buy corresponds to label-1 and a \"no\" in Buy corresponds to label-0.\n",
    "\n",
    "<br>**Instructions to follow for learning a Baeysian classifier:** *(Code the formulae for estimating the different parameters yourself)*\n",
    "<br> a)Estimate the prior probability: $P(Y=1)$  ⟶ which could be referred to as: $\\hat{a}$   \n",
    "b)Estimate the likelihood for each feature:  $P(X_{i,j} = x |Y = y_{i})$, where $ i$=datapoint counter, $j \\in \\{1,2,3\\}$ and $y_{i} \\in \\{0,1\\}$ \n",
    "<br>c)Estimate the total likelihood: $P(X_{i} = x |Y = y_{i})$  \n",
    "d)Calculate the posterior probability: $P(Y = 1|X_{i} = x_{test} )$ = $p_{test}$ where $x_{test} = (Age = 21-30, Income= medium, Status = married)$\n",
    "\n",
    "\n",
    "Return back: $\\hat{a}$, total likelihood and $p_{test}$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_data = \"\"\"\n",
    "Age  | Income | Status  | Buy\n",
    "-----|--------|-------- |----\n",
    "<=20 |  low   | students| yes\n",
    "<=20 |  high  | students| yes\n",
    "<=20 | medium | students| no\n",
    "<=20 | medium | married | no\n",
    "<=20 |  high  | married | yes\n",
    "21-30|  low   | married | yes\n",
    "21-30|  low   | married | no \n",
    "21-30| medium | students| no\n",
    "21-30|  high  | students| yes\n",
    " >30 |  high  | married | no\n",
    " >30 |  high  | married | yes\n",
    " >30 | medium | married | yes\n",
    " >30 | medium | married | no\n",
    " >30 | medium | students| no\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_data = discrete_data.split(\"\\n\")[1:]\n",
    "\n",
    "age = []\n",
    "income = []\n",
    "status = []\n",
    "buy = []\n",
    "\n",
    "for i in range(2, len(discrete_data)):\n",
    "    p, q, r, s = [line.strip() for line in discrete_data[i].split(\"|\")]\n",
    "    age.append(p)\n",
    "    income.append(q)\n",
    "    status.append(r)\n",
    "    buy.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [age, income, status]\n",
    "values = {\"age\": age, \"income\": income, \"status\": status}\n",
    "n = len(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probability of Y = 1: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Prior probability\n",
    "pr1 = buy.count(\"yes\")/n\n",
    "print(\"Prior Probability of Y = 1:\", pr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_loc = []\n",
    "neg_loc = []\n",
    "for k in range(n):\n",
    "    if buy[k]==\"yes\":\n",
    "        pos_loc.append(k)\n",
    "    else:\n",
    "        neg_loc.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood for each of the features\n",
    "prob = {\"yes\":{}, \"no\":{}}\n",
    "\n",
    "for i in values:\n",
    "    unique_vals = set(values[i])\n",
    "    prob[\"yes\"][i] = {}\n",
    "    prob[\"no\"][i] = {}\n",
    "    \n",
    "    for j in unique_vals:\n",
    "        countp = 0\n",
    "        countn = 0\n",
    "        \n",
    "        for k in range(n):\n",
    "            if buy[k]=='yes' and values[i][k]==j:\n",
    "                countp += 1\n",
    "            if buy[k]=='no' and values[i][k]==j:\n",
    "                countn += 1\n",
    "                \n",
    "        prob[\"yes\"][i][j] = countp/len(pos_loc)\n",
    "        prob[\"no\"][i][j] = countn/len(neg_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(X_age=>30 | Y=yes) = 0.2857142857142857\n",
      "P(X_age=21-30 | Y=yes) = 0.2857142857142857\n",
      "P(X_age=<=20 | Y=yes) = 0.42857142857142855\n",
      "\n",
      "P(X_income=high | Y=yes) = 0.5714285714285714\n",
      "P(X_income=medium | Y=yes) = 0.14285714285714285\n",
      "P(X_income=low | Y=yes) = 0.2857142857142857\n",
      "\n",
      "P(X_status=students | Y=yes) = 0.42857142857142855\n",
      "P(X_status=married | Y=yes) = 0.5714285714285714\n",
      "\n",
      "P(X_age=>30 | Y=no) = 0.42857142857142855\n",
      "P(X_age=21-30 | Y=no) = 0.2857142857142857\n",
      "P(X_age=<=20 | Y=no) = 0.2857142857142857\n",
      "\n",
      "P(X_income=high | Y=no) = 0.14285714285714285\n",
      "P(X_income=medium | Y=no) = 0.7142857142857143\n",
      "P(X_income=low | Y=no) = 0.14285714285714285\n",
      "\n",
      "P(X_status=students | Y=no) = 0.42857142857142855\n",
      "P(X_status=married | Y=no) = 0.5714285714285714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature wise Conditional Probabilities\n",
    "for i in prob:\n",
    "    for j in prob[i]:\n",
    "        for k in prob[i][j]:\n",
    "            print(\"P(X_{}={} | Y={}) = {}\".format(j, k, i, prob[i][j][k]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Probability\n",
    "age_values = set(list(age))\n",
    "income_values = set(list(income))\n",
    "status_values = set(list(status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Y=1\n",
      "P(X age = >30; income = high; status = students | Y = 1) = 0.06997084548104955\n",
      "P(X age = >30; income = high; status = married | Y = 1) = 0.0932944606413994\n",
      "P(X age = >30; income = medium; status = students | Y = 1) = 0.017492711370262388\n",
      "P(X age = >30; income = medium; status = married | Y = 1) = 0.02332361516034985\n",
      "P(X age = >30; income = low; status = students | Y = 1) = 0.034985422740524776\n",
      "P(X age = >30; income = low; status = married | Y = 1) = 0.0466472303206997\n",
      "P(X age = 21-30; income = high; status = students | Y = 1) = 0.06997084548104955\n",
      "P(X age = 21-30; income = high; status = married | Y = 1) = 0.0932944606413994\n",
      "P(X age = 21-30; income = medium; status = students | Y = 1) = 0.017492711370262388\n",
      "P(X age = 21-30; income = medium; status = married | Y = 1) = 0.02332361516034985\n",
      "P(X age = 21-30; income = low; status = students | Y = 1) = 0.034985422740524776\n",
      "P(X age = 21-30; income = low; status = married | Y = 1) = 0.0466472303206997\n",
      "P(X age = <=20; income = high; status = students | Y = 1) = 0.10495626822157432\n",
      "P(X age = <=20; income = high; status = married | Y = 1) = 0.1399416909620991\n",
      "P(X age = <=20; income = medium; status = students | Y = 1) = 0.02623906705539358\n",
      "P(X age = <=20; income = medium; status = married | Y = 1) = 0.034985422740524776\n",
      "P(X age = <=20; income = low; status = students | Y = 1) = 0.05247813411078716\n",
      "P(X age = <=20; income = low; status = married | Y = 1) = 0.06997084548104955\n"
     ]
    }
   ],
   "source": [
    "print(\"For Y=1\")\n",
    "for i in age_values:\n",
    "    for j in income_values:\n",
    "        for k in status_values:\n",
    "            result = prob[\"yes\"][\"age\"][i] * prob[\"yes\"][\"income\"][j] * prob[\"yes\"][\"status\"][k]\n",
    "            print(\"P(X age = {}; income = {}; status = {} | Y = 1) = {}\".format(i, j, k, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Y=0\n",
      "P(X age = >30; income = high; status = students | Y = 0) = 0.02623906705539358\n",
      "P(X age = >30; income = high; status = married | Y = 0) = 0.034985422740524776\n",
      "P(X age = >30; income = medium; status = students | Y = 0) = 0.13119533527696792\n",
      "P(X age = >30; income = medium; status = married | Y = 0) = 0.1749271137026239\n",
      "P(X age = >30; income = low; status = students | Y = 0) = 0.02623906705539358\n",
      "P(X age = >30; income = low; status = married | Y = 0) = 0.034985422740524776\n",
      "P(X age = 21-30; income = high; status = students | Y = 0) = 0.017492711370262388\n",
      "P(X age = 21-30; income = high; status = married | Y = 0) = 0.02332361516034985\n",
      "P(X age = 21-30; income = medium; status = students | Y = 0) = 0.08746355685131195\n",
      "P(X age = 21-30; income = medium; status = married | Y = 0) = 0.11661807580174927\n",
      "P(X age = 21-30; income = low; status = students | Y = 0) = 0.017492711370262388\n",
      "P(X age = 21-30; income = low; status = married | Y = 0) = 0.02332361516034985\n",
      "P(X age = <=20; income = high; status = students | Y = 0) = 0.017492711370262388\n",
      "P(X age = <=20; income = high; status = married | Y = 0) = 0.02332361516034985\n",
      "P(X age = <=20; income = medium; status = students | Y = 0) = 0.08746355685131195\n",
      "P(X age = <=20; income = medium; status = married | Y = 0) = 0.11661807580174927\n",
      "P(X age = <=20; income = low; status = students | Y = 0) = 0.017492711370262388\n",
      "P(X age = <=20; income = low; status = married | Y = 0) = 0.02332361516034985\n"
     ]
    }
   ],
   "source": [
    "print(\"For Y=0\")\n",
    "for i in age_values:\n",
    "    for j in income_values:\n",
    "        for k in status_values:\n",
    "            result = prob[\"no\"][\"age\"][i] * prob[\"no\"][\"income\"][j] * prob[\"no\"][\"status\"][k]\n",
    "            print(\"P(X age = {}; income = {}; status = {} | Y = 0) = {}\".format(i, j, k, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Y=1 | xtest = Age=21-30,Income=medium,Status=married) = 0.16666666666666663\n",
      "P(Y=0 | xtest = Age=21-30,Income=medium,Status=married) = 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "given_age = \"21-30\"\n",
    "given_income = \"medium\"\n",
    "given_status = \"married\"\n",
    "\n",
    "conditional_yes = prob[\"yes\"][\"age\"][given_age] * prob[\"yes\"][\"income\"][given_income] * prob[\"yes\"][\"status\"][given_status]\n",
    "conditional_no = prob[\"no\"][\"age\"][given_age] * prob[\"no\"][\"income\"][given_income] * prob[\"no\"][\"status\"][given_status]\n",
    "probability = (conditional_yes * pr1)/((conditional_yes * pr1) + (conditional_no * (1 - pr1)))\n",
    "\n",
    "print(\"P(Y=1 | xtest = Age={},Income={},Status={}) = {}\".format(given_age, given_income, given_status, probability))\n",
    "print(\"P(Y=0 | xtest = Age={},Income={},Status={}) = {}\".format(given_age, given_income, given_status, 1-probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write results here:\n",
    "\n",
    "The posterior probability for x_test when Y = 1 is 0.16666666666666663, and is 0.8333333333333334 when Y=0\n",
    "Therefore the prediction is \"No\" or 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
